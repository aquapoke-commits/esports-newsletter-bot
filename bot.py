import discord
from discord.ext import commands
import requests
from bs4 import BeautifulSoup
import feedparser
import html
import os
# [ì¤‘ìš”] ì •í™•í•œ ì‹œê°„ ê³„ì‚°ì„ ìœ„í•´ timezone í•„ìˆ˜
from datetime import datetime, timedelta, timezone
import asyncio

# =====================================================================
# [ë³´ì•ˆ ì„¤ì •]
# =====================================================================
if 'DISCORD_TOKEN' in os.environ:
    DISCORD_TOKEN = os.environ['DISCORD_TOKEN']
else:
    print("âš ï¸ ì—ëŸ¬: DISCORD_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# [ì„¤ì •] ì±„ë„ ID ë¦¬ìŠ¤íŠ¸
TARGET_CHANNELS = [
    1447898781365567580, # GGX Proto
    1450833963278012558, # Hanta.GG
    987654321098765432,  # í…ŒìŠ¤íŠ¸ìš©
]

# [ì„¤ì •] ê²€ìƒ‰ì–´ ëª©ë¡
KEYWORDS = ["ì´ìŠ¤í¬ì¸ ", "LCK", "VCT", "ì´í„°ë„ ë¦¬í„´ ì´ìŠ¤í¬ì¸ ", "PUBG", "í‹°ì›", "Faker", "Gen.G", "HLE", "kt Rolster", "ë””í”ŒëŸ¬ìŠ¤ ê¸°ì•„", "í”¼ì–´ì—‘ìŠ¤", "ë†ì‹¬ ë ˆë“œí¬ìŠ¤", "í•œì§„ ë¸Œë¦¬ì˜¨", "DRX", "DN SOOPers"]

# [ì„¤ì •] ì°¨ë‹¨í•  ë‹¨ì–´ (ì†Œë¬¸ì)
EXCLUDE_LIST = ["theqoo", "ë”ì¿ ", "instiz", "fmkorea", "dcinside", "ë””ì‹œ", "ë°”ì¹´ë¼"]

# [ì„¤ì •] ë‰´ìŠ¤ ìœ íš¨ ì‹œê°„ (ë‹¨ìœ„: ì‹œê°„)
# 24ì‹œê°„ì´ ë„ˆë¬´ ë„ë„í•˜ë©´ 18~20ì‹œê°„ìœ¼ë¡œ ì¤„ì´ì„¸ìš”.
MAX_HOURS = 24

# ë´‡ ì„¤ì •
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# ---------------------------------------------------
# [í¬ë¡¤ë§ í•¨ìˆ˜] - ì‘ì„± ì‹œê°„ ë¡œê·¸ ì¶”ê°€
# ---------------------------------------------------
def get_naver_news(keyword):
    news_list = []
    clean_keyword = keyword.replace(" ", "+")
    url = f"https://search.naver.com/search.naver?where=news&query={clean_keyword}&sort=1"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # [ìˆ˜ì •] ê°€ì¥ ì•ˆì „í•œ ë°©ë²•: ë¦¬ìŠ¤íŠ¸ í•­ëª©(li.bx)ì„ ë¨¼ì € ì°¾ìŠµë‹ˆë‹¤.
        items = soup.select('ul.list_news > li.bx')
        
        # print(f"ğŸ” [ë„¤ì´ë²„] '{keyword}' ê²€ìƒ‰ê²°ê³¼: {len(items)}ê°œ ë°œê²¬") 
        
        for item in items:
            # ì œëª©ì´ ì—†ìœ¼ë©´ ë‰´ìŠ¤ ì•„ë‹˜ (íŒ¨ìŠ¤)
            title_tag = item.select_one('a.news_tit')
            if not title_tag: continue
            
            title = title_tag.text
            link = title_tag['href']
            
            # [Naver ì‹œê°„ ì •ë°€ ê²€ì‚¬]
            # info_groupì´ ì—†ì„ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            info_group = item.select('.info_group .info')
            is_recent = False
            time_log = "ì•Œìˆ˜ì—†ìŒ"
            
            for info in info_group:
                text = info.text
                if "ë¶„ ì „" in text or "ì‹œê°„ ì „" in text:
                    time_log = text 
                    if "ì¼ ì „" in text:
                        # print(f"â° [ë„¤ì´ë²„|íƒˆë½] {keyword} | {title} (ì‚¬ìœ : '{text}' - ìˆ˜ì •ëœ êµ¬ ê¸°ì‚¬)")
                        is_recent = False
                        break
                    is_recent = True
                    break
            
            if is_recent:
                news_list.append({
                    "title": title, 
                    "link": link, 
                    "source": "Naver", 
                    "origin": "ë„¤ì´ë²„",
                    "time_str": time_log 
                })

    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ ì˜¤ë¥˜({keyword}): {e}")
        pass
    return news_list

def get_google_news(keyword):
    news_list = []
    clean_keyword = keyword.replace(" ", "+")
    url = f"https://news.google.com/rss/search?q={clean_keyword}+when:1d&hl=ko&gl=KR&ceid=KR:ko"
    
    # [ì—°ë„ í•„í„°] êµ¬ê¸€ì´ 2026ë…„ì¸ë° 2025ë…„ ê¸°ì‚¬ë¥¼ 'ì˜¤ëŠ˜'ë¡œ ì°©ê°í•´ì„œ ë³´ë‚¼ ë•Œ ê±°ë¥´ê¸° ìœ„í•¨
    # í˜„ì¬ ì—°ë„(2026)ê°€ ì•„ë‹Œ ê³¼ê±° ì—°ë„ê°€ ì œëª©ì— ìˆìœ¼ë©´ ì˜ì‹¬
    PAST_YEARS = ["2020", "2021", "2022", "2023", "2024", "2025"] 

    try:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if not hasattr(entry, 'published_parsed') or entry.published_parsed is None:
                continue
            
            try:
                # 1. ì‹œê°„ ê³„ì‚° (UTC)
                pub_date = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
                current_date = datetime.now(timezone.utc)
                
                diff_seconds = (current_date - pub_date).total_seconds()
                diff_hours = diff_seconds / 3600
                if diff_hours < 0: diff_hours = 0
                
                pub_date_kst = pub_date + timedelta(hours=9)
                time_str_kst = pub_date_kst.strftime("%Y-%m-%d %H:%M:%S")

                source_name = "Google"
                if hasattr(entry, 'source') and hasattr(entry.source, 'title'):
                    source_name = entry.source.title

                # [ì‹œê°„ ì œí•œ]
                if diff_hours > MAX_HOURS:
                    print(f"â° [êµ¬ê¸€|íƒˆë½] {keyword} | {entry.title} (ì‘ì„±ì‹œê°„: {time_str_kst})")
                    continue
                
                # [ì¶”ê°€ í•„í„°] ì œëª©ì— ê³¼ê±° ì—°ë„ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì‚¬ (ì˜ˆ: ê¹€ì •ê·  ê°ë… 2025...)
                is_old_title = False
                for year in PAST_YEARS:
                    # ì œëª©ì—ëŠ” ìˆëŠ”ë°, ë¬¸ë§¥ìƒ '2025 ì‹œì¦Œ ê²°ì‚°' ê°™ì€ ê±´ í†µê³¼ì‹œì¼œì•¼ í•  ìˆ˜ë„ ìˆìŒ.
                    # í•˜ì§€ë§Œ ì§€ê¸ˆì²˜ëŸ¼ 'ì—‰ëš±í•œ ì˜›ë‚  ê¸°ì‚¬'ê°€ ë¬¸ì œë¼ë©´ ê³¼ê°íˆ ê±°ë¥´ëŠ” ê²Œ ë‚«ìŠµë‹ˆë‹¤.
                    if year in entry.title:
                         # í˜„ì¬ê°€ 2026ë…„ 1ì›”ì´ë¯€ë¡œ '2025'ëŠ” ë†”ë‘˜ì§€ ê³ ë¯¼ë˜ì§€ë§Œ, 
                         # ëª…í™•í•œ ê³¼ê±° ê¸°ì‚¬ ì¬íƒ•ì„ ë§‰ìœ¼ë ¤ë©´ ê±°ë¥´ëŠ”ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.
                         # (í•„ìš”ì‹œ ë¦¬ìŠ¤íŠ¸ì—ì„œ "2025"ëŠ” ë¹¼ì„¸ìš”)
                         is_old_title = True
                         print(f"ğŸ“… [êµ¬ê¸€|ì—°ë„íƒˆë½] {entry.title} (ì´ìœ : ê³¼ê±° ì—°ë„ '{year}' í¬í•¨)")
                         break
                if is_old_title: continue

                news_list.append({
                    "title": entry.title,
                    "link": entry.link,
                    "source": source_name,
                    "origin": "êµ¬ê¸€",
                    "time_str": time_str_kst
                })
                
            except:
                continue
                
    except Exception as e:
        print(f"âŒ êµ¬ê¸€ ì˜¤ë¥˜({keyword}): {e}")
        pass
        
    return news_list
    
# ---------------------------------------------------
# [ì „ì†¡ ë¡œì§]
# ---------------------------------------------------
async def send_newsletter(target_channel_id, news_data):
    channel = bot.get_channel(target_channel_id)
    if not channel:
        print(f"âŒ ì±„ë„ ì—†ìŒ: {target_channel_id}")
        return

    if not news_data:
        return

    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    MAX_DESCRIPTION_LEN = 3500
    current_description = ""
    page_count = 1
    
    embed = discord.Embed(title=f"ğŸ® {today} ì´ìŠ¤í¬ì¸  ì£¼ìš” ì†Œì‹", color=0x00ff00)

    for idx, news in enumerate(news_data):
        one_line = f"` {idx+1}. ` [{news['title']}]({news['link']})\n\n"
        
        if len(current_description) + len(one_line) > MAX_DESCRIPTION_LEN:
            embed.description = current_description
            embed.set_footer(text=f"HantaGG NewsBot â€¢ {page_count}í˜ì´ì§€")
            await channel.send(embed=embed)
            page_count += 1
            current_description = ""
            embed = discord.Embed(color=0x00ff00)
            
        current_description += one_line

    if current_description:
        embed.description = current_description
        embed.set_footer(text=f"HantaGG NewsBot â€¢ ë§ˆì§€ë§‰ í˜ì´ì§€ (ì´ {len(news_data)}ê±´)")
        await channel.send(embed=embed)

    print(f"âœ… ì „ì†¡ ì™„ë£Œ: {target_channel_id}")

# ---------------------------------------------------
# [ë´‡ ì‹¤í–‰]
# ---------------------------------------------------
@bot.event
async def on_ready():
    print(f"âœ… ë´‡ ë¡œê·¸ì¸: {bot.user}")
    
    todays_news = collect_news()
    
    for channel_id in TARGET_CHANNELS:
        await send_newsletter(channel_id, todays_news)
    
    print("ğŸ‘‹ ì„ë¬´ ì™„ë£Œ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
    await bot.close()

if __name__ == "__main__":
    bot.run(DISCORD_TOKEN)







